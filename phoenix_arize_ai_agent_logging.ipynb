{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9acb9a73-8e7f-4daa-aa33-493745d79a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/contextlib.py:142: SAWarning: Skipped unsupported reflection of expression-based index ix_cumulative_llm_token_count_total\n",
      "  next(self.gen)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/contextlib.py:142: SAWarning: Skipped unsupported reflection of expression-based index ix_latency\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit https://test2.notebook.us-east-1.sagemaker.aws/proxy/6006/\n",
      "üìñ For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\n",
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: oisin-test\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: localhost:4317\n",
      "|  Transport: gRPC\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  ‚ö†Ô∏è WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n",
      "Total Steps: 4\n",
      "Tools Used: 0\n",
      "Reasoning Steps: 0\n",
      "Final Response: \n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "    \"function\": \"user__askuser\",\n",
      "    \"parameters\": {\n",
      "        \"question\": \"Could you please specify which Melbourne you're referring to? (e.g., Melbourne, Australia or Melbourne, Florida, USA)\"\n",
      "    }\n",
      "}\n",
      "üì∫ Opening a view to the Phoenix app. The app is running at https://test2.notebook.us-east-1.sagemaker.aws/proxy/6006/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1000\"\n",
       "            src=\"https://test2.notebook.us-east-1.sagemaker.aws/proxy/6006/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f341d8e3fd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -q arize-phoenix openinference-instrumentation-bedrock\n",
    "\n",
    "import phoenix as px\n",
    "import os\n",
    "import boto3\n",
    "import time\n",
    "import json\n",
    "from phoenix.otel import register\n",
    "\n",
    "session = px.launch_app()\n",
    "\n",
    "tracer_provider = register(\n",
    "    project_name=\"cerulion-test\",\n",
    "    auto_instrument=True\n",
    ")\n",
    "\n",
    "session = boto3.session.Session()\n",
    "bedrock_agent_client = session.client(\n",
    "    \"bedrock-agent-runtime\",\n",
    "    region_name=\"us-east-1\"\n",
    ")\n",
    "\n",
    "AGENT_ID = \"<your-agent-id>\"\n",
    "AGENT_ALIAS_ID = \"TSTALIASID\" # replace TSTALIASID with your agent alias id, otherwise leave it and it will use the latest version\n",
    "\n",
    "def debug_bedrock_agent(input_text, verbose=True):\n",
    "    session_id = f\"sagemaker_session_{int(time.time())}\"\n",
    "    \n",
    "    attributes = {\n",
    "        \"inputText\": input_text,\n",
    "        \"agentId\": AGENT_ID,\n",
    "        \"agentAliasId\": AGENT_ALIAS_ID,\n",
    "        \"sessionId\": session_id,\n",
    "        \"enableTrace\": True,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = bedrock_agent_client.invoke_agent(**attributes)\n",
    "        \n",
    "        full_response = \"\"\n",
    "        step_count = 0\n",
    "        tool_calls = []\n",
    "        reasoning_steps = []\n",
    "        \n",
    "        for event in response.get(\"completion\", []):\n",
    "            if \"chunk\" in event:\n",
    "                chunk = event[\"chunk\"]\n",
    "                if \"bytes\" in chunk:\n",
    "                    text = chunk[\"bytes\"].decode()\n",
    "                    full_response += text\n",
    "            \n",
    "            if \"trace\" in event:\n",
    "                step_count += 1\n",
    "                trace = event[\"trace\"]\n",
    "                \n",
    "                if \"orchestrationTrace\" in trace:\n",
    "                    orch = trace[\"orchestrationTrace\"]\n",
    "                    \n",
    "                    if \"rationale\" in orch:\n",
    "                        reasoning = orch[\"rationale\"][\"text\"]\n",
    "                        reasoning_steps.append(reasoning)\n",
    "                        if verbose:\n",
    "                            print(f\"Step {step_count} Reasoning: {reasoning}\")\n",
    "                    \n",
    "                    if \"invocationInput\" in orch:\n",
    "                        inv_input = orch[\"invocationInput\"]\n",
    "                        if \"actionGroupInvocationInput\" in inv_input:\n",
    "                            action_input = inv_input[\"actionGroupInvocationInput\"]\n",
    "                            tool_name = action_input.get(\"actionGroupName\", \"Unknown\")\n",
    "                            function_name = action_input.get(\"function\", \"Unknown\")\n",
    "                            parameters = action_input.get(\"parameters\", {})\n",
    "                            \n",
    "                            tool_call = {\n",
    "                                \"tool\": tool_name,\n",
    "                                \"function\": function_name,\n",
    "                                \"parameters\": parameters\n",
    "                            }\n",
    "                            tool_calls.append(tool_call)\n",
    "                            \n",
    "                            if verbose:\n",
    "                                print(f\"Tool Called: {tool_name} - {function_name}\")\n",
    "                                print(f\"Parameters: {parameters}\")\n",
    "                    \n",
    "                    if \"observation\" in orch:\n",
    "                        obs = orch[\"observation\"]\n",
    "                        if \"actionGroupInvocationOutput\" in obs:\n",
    "                            output = obs[\"actionGroupInvocationOutput\"]\n",
    "                            result_text = output.get(\"text\", \"No text output\")\n",
    "                            if verbose:\n",
    "                                print(f\"Tool Result: {result_text}\")\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Total Steps: {step_count}\")\n",
    "            print(f\"Tools Used: {len(tool_calls)}\")\n",
    "            print(f\"Reasoning Steps: {len(reasoning_steps)}\")\n",
    "            print(f\"Final Response: {full_response}\")\n",
    "        \n",
    "        return {\n",
    "            \"response\": full_response,\n",
    "            \"session_id\": session_id,\n",
    "            \"steps\": step_count,\n",
    "            \"tool_calls\": tool_calls,\n",
    "            \"reasoning_steps\": reasoning_steps,\n",
    "            \"success\": True\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "        \n",
    "        return {\n",
    "            \"response\": None,\n",
    "            \"session_id\": session_id,\n",
    "            \"error\": str(e),\n",
    "            \"success\": False\n",
    "        }\n",
    "\n",
    "test_input = \"What's the weather like in Melbourne today?\"\n",
    "result = debug_bedrock_agent(test_input, verbose=True)\n",
    "\n",
    "px.active_session().view()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
